{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras import initializers, layers, callbacks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.45\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASSES = 10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=NCLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=NCLASSES)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Length(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "def squash(inputs):\n",
    "    s_squared_norm = K.sum(K.square(inputs), axis=-1, keepdims=True)\n",
    "    scale = (s_squared_norm / (1 + s_squared_norm))\n",
    "    return scale * inputs / K.sqrt(s_squared_norm)    \n",
    "def margin_loss(y_true, y_pred):\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) +  0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capsule network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### capsule layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_capsule, dim_vector, num_routing=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 name='digitcaps'):\n",
    "        super(DigitCaps, self).__init__(name=name) # s√≥  pra  colocar nome nesta merda\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_vector = dim_vector\n",
    "        self.num_routing = num_routing\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "    def build(self, input_shape):\n",
    "        # shoud be [None,input_num_capsule,input_dim_vector]\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_vector = input_shape[2]\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.W_ij = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dim_vector],\n",
    "                                    initializer=self.kernel_initializer,name='W_ij')\n",
    "        self.b_i = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1],\n",
    "                                   initializer=self.bias_initializer,name='b_i', trainable=False)\n",
    "    def call(self, inputs, training=None):\n",
    "        # [None, input_num_capsule, input_dim_vector]\n",
    "        u_i = K.expand_dims(K.expand_dims(inputs, 2), 2)# [None, input_num_capsule, 1, 1, input_dim_vector]\n",
    "        u_i = K.tile(u_i, [1, 1, self.num_capsule, 1, 1]) # [None, input_num_capsule, num_capsule, 1, input_dim_vector]\n",
    "        u_hat_ji = tf.scan(lambda ac, x: K.batch_dot(x, self.W_ij, [3, 2]), elems=u_i,\n",
    "                             initializer=K.zeros([self.input_num_capsule, self.num_capsule, 1, self.dim_vector]))\n",
    "        for i in range(self.num_routing):\n",
    "            c_ij = tf.nn.softmax(self.b_i, dim=2)  \n",
    "            v_j = squash(K.sum(c_ij * u_hat_ji, 1, keepdims=True))\n",
    "            if i != self.num_routing - 1:\n",
    "                self.b_i += K.sum(u_hat_ji * v_j, -1, keepdims=True)\n",
    "        return K.reshape(v_j, [-1, self.num_capsule, self.dim_vector])\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_vector])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### primary caps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n",
    "    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n",
    "    return layers.Lambda(squash)(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "Tensor(\"dsf_7/Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_72 (InputLayer)            (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 20, 20, 256)   20992       input_72[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 6, 6, 256)     5308672     conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "reshape_40 (Reshape)             (None, 1152, 8)       0           conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)               (None, 1152, 8)       0           reshape_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "digitcaps (DigitCaps)            (None, 10, 16)        1486080     lambda_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_73 (InputLayer)            (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)               (None, 16)            0           digitcaps[0][0]                  \n",
      "                                                                   input_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 512)           8704        lambda_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 1024)          525312      dense_63[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 784)           803600      dense_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "vj_abs (Length)                  (None, 10)            0           digitcaps[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dsf (Reshape)                    (None, 28, 28, 1)     0           dense_65[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 8,153,360\n",
      "Trainable params: 8,141,840\n",
      "Non-trainable params: 11,520\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=[28, 28, 1]\n",
    "num_routing=3\n",
    "x = layers.Input(shape=input_shape)\n",
    "# Conv1\n",
    "conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "# primary caps\n",
    "primarycaps = PrimaryCap(conv1, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "# digit caps\n",
    "digitcaps = DigitCaps(num_capsule=NCLASSES, dim_vector=16, num_routing=num_routing,name='digitcaps')(primarycaps)\n",
    "# predicted label\n",
    "#     v_j_abs = keras.layers.Lambda(Length)(digitcaps)\n",
    "v_j_abs = Length(name='vj_abs')(digitcaps)\n",
    "## Reconstruction for regulariation\n",
    "y = layers.Input(shape=(NCLASSES,))\n",
    "\n",
    "def Mask(inputs): \n",
    "    return K.batch_dot(inputs[0], inputs[1], [1, 1])\n",
    "\n",
    "masked = layers.Lambda(Mask)([digitcaps, y])\n",
    "# masked = Mask()([digitcaps, y])\n",
    "l = layers.Dense(512, activation='relu')(masked)\n",
    "l = layers.Dense(1024, activation='relu')(l)\n",
    "l = layers.Dense(784, activation='sigmoid')(l)\n",
    "print(l.shape)\n",
    "decoded = layers.Reshape(target_shape=[28, 28, 1], name='dsf')(l)\n",
    "print(decoded)\n",
    "model = keras.models.Model([x, y], [v_j_abs, decoded])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, data, epocs):\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=0.0001),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., 28*28*0.0005],\n",
    "                  metrics={'v_j_abs': 'accuracy'})    \n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=256, epochs=epocs,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=model, data=((x_train, y_train), (x_test, y_test)), epocs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
